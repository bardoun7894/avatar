# Avatar App - Cursor IDE Development Rules

## ğŸ¯ Project Overview

**Purpose:** Arabic AI Avatar with Real-time Conversation, Visual Context Awareness, and Data Persistence
**Backend:** Python + LiveKit Agents (avatary/)
**Frontend:** Next.js + React + LiveKit Components (frontend/)
**Database:** Supabase (PostgreSQL)
**Main Use Case:** Ornina company customer service bot with vision capabilities

---

## ğŸ“ Project Structure

```
/var/www/avatar /
â”œâ”€â”€ avatary/                           # Python backend
â”‚   â”œâ”€â”€ agent.py                       # â­ MAIN - Agent orchestrator
â”‚   â”œâ”€â”€ visual_aware_agent.py          # â­ Custom agent with visual context injection
â”‚   â”œâ”€â”€ visual_context_models.py       # â­ Pydantic models for visual data
â”‚   â”œâ”€â”€ vision_processor.py            # Video frame capture & GPT-4 Vision
â”‚   â”œâ”€â”€ vision_agent.py                # Video track monitoring
â”‚   â”œâ”€â”€ prompts.py                     # Arabic agent instructions
â”‚   â”œâ”€â”€ professional_conversation_manager.py  # Conversation buffering + DB
â”‚   â”œâ”€â”€ knowledge_base_manager.py      # Supabase queries
â”‚   â”œâ”€â”€ local_mcp_server.py            # MCP tool definitions
â”‚   â”œâ”€â”€ users_manager.py               # User data management
â”‚   â”œâ”€â”€ consultation_manager.py        # Consultation booking
â”‚   â”œâ”€â”€ inquiry_manager.py             # Customer inquiries
â”‚   â”œâ”€â”€ training_manager.py            # Training enrollments
â”‚   â””â”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ frontend/                          # Next.js frontend
    â”œâ”€â”€ pages/
    â”‚   â”œâ”€â”€ index.tsx                  # Main page
    â”‚   â””â”€â”€ api/
    â”‚       â”œâ”€â”€ token.ts               # LiveKit token
    â”‚       â””â”€â”€ dispatch-agent.ts      # Agent dispatch
    â””â”€â”€ components/
        â”œâ”€â”€ VideoCallInterface.tsx
        â””â”€â”€ ControlBar.tsx
```

---

## ğŸ—ï¸ Architecture Patterns (MUST FOLLOW)

### 1. Visual Context Pattern â­ CRITICAL
**Current Implementation (Working):**
- Uses `VisualAwareAgent` class that extends LiveKit Agent
- Overrides `llm_node` method to inject visual context
- Visual context stored in Pydantic `VisualContextStore`
- Context injected as system message before EACH LLM call

**How It Works:**
```python
class VisualAwareAgent(Agent):
    async def llm_node(self, chat_ctx, tools, model_settings):
        # Get fresh visual analysis from Pydantic store
        current_visual = self.visual_store.get_current()

        if current_visual and current_visual.is_fresh:
            # Inject as system message
            chat_ctx.add_message(
                role="system",
                content=current_visual.to_injection_text()
            )

        # Delegate to default processing
        async for chunk in Agent.default.llm_node(self, chat_ctx, tools, model_settings):
            yield chunk
```

**DO:**
- âœ… Use VisualAwareAgent for all agent instances
- âœ… Update visual context via `agent.update_visual_context(analysis)`
- âœ… Let the llm_node override handle automatic injection
- âœ… Check freshness via `visual_store.get_current().is_fresh`

**DON'T:**
- âŒ Update agent.instructions directly (won't work with Tavus caching)
- âŒ Use session.say() to inject context (pollutes conversation)
- âŒ Prepend context to user messages (hard to maintain)

### 2. Conversation Management Pattern
**Current:** `ProfessionalConversationManager`
```python
# Local buffering (zero-lag) + Database persistence
prof_manager = ProfessionalConversationManager()
prof_manager.add_message(role="user", content="...")
# ... at call end:
prof_manager.save_to_database(room_name, user_id)
```

**DO:**
- âœ… Use ProfessionalConversationManager only
- âœ… Buffer messages locally during call
- âœ… Save to database on call end
- âœ… Implement buffer size limits (max 100 messages)

**DON'T:**
- âŒ Use conversation_logger.py (deprecated)
- âŒ Use conversation_context_manager.py (deprecated, use VisualAwareAgent)
- âŒ Write to database on every message (too slow)

### 3. Knowledge Base Pattern
```python
# Async search with caching (when implemented)
results = await kb_manager.smart_search(query)
```

**DO:**
- âœ… Use async/await for all DB operations
- âœ… Implement caching layer (Redis, TTL: 5 min)
- âœ… Use connection pooling (singleton pattern)

**DON'T:**
- âŒ Synchronous DB calls in async context
- âŒ Create new Supabase client per query
- âŒ Skip caching for frequently accessed data

### 4. Tool Registration Pattern
```python
# In agent.py
from local_mcp_server import create_mcp_tools

tools = create_mcp_tools()
for tool in tools:
    agent_session.register_tool(tool)
```

---

## ğŸ“‹ Implementation Checklist (Reference Plan)

### âœ… COMPLETED (Don't Redo)
- [x] Visual context injection system (VisualAwareAgent)
- [x] Pydantic models for visual data
- [x] Professional conversation manager
- [x] Knowledge base integration (Supabase)
- [x] User data extraction and management
- [x] Arabic voice support (OpenAI TTS "alloy")
- [x] MCP tools for knowledge base search
- [x] Frame capture and GPT-4 Vision analysis
- [x] Fix ModelSettings import bug âš ï¸ CRITICAL FIX APPLIED

### ğŸš§ IN PROGRESS (Current Sprint)
- [ ] Docker setup (Dockerfile + docker-compose.yml)
- [ ] Redis caching layer
- [ ] Async database operations
- [ ] Connection pooling
- [ ] Performance optimizations

### ğŸ“ TODO (Future Work)
- [ ] Comprehensive test suite
- [ ] Structured logging (JSON format)
- [ ] Health check endpoint
- [ ] Rate limiting for APIs
- [ ] Monitoring and metrics
- [ ] Production deployment guide

---

## ğŸ’» Code Standards

### Python Style
```python
# âœ… GOOD: Type hints, async, Pydantic
async def search_products(query: str) -> List[Product]:
    """Search products in knowledge base."""
    results = await kb_manager.search(query)
    return [Product(**r) for r in results]

# âŒ BAD: No types, sync in async context
def search_products(query):
    results = kb_manager.search(query)  # Blocking!
    return results
```

### Naming Conventions
- **Files:** `snake_case.py`
- **Classes:** `PascalCase`
- **Functions:** `snake_case`
- **Constants:** `UPPER_SNAKE_CASE`
- **Private:** `_leading_underscore`

### Documentation
```python
def create_agent(instructions: str) -> VisualAwareAgent:
    """
    Create a visual-aware agent instance.

    Args:
        instructions: Base Arabic instructions for the agent

    Returns:
        VisualAwareAgent instance with visual context injection

    Example:
        >>> agent = create_agent("Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ornina")
        >>> agent.update_visual_context("Ø£Ø±Ù‰ Ø´Ø®ØµÙ‹Ø§...")
    """
    visual_store = VisualContextStore()
    return VisualAwareAgent(instructions, visual_store)
```

---

## ğŸš¨ Critical Rules

### 1. Import Pattern (FIXED - Nov 7, 2025)
```python
# âœ… CORRECT (after fix)
from livekit.agents import Agent, llm
from typing import AsyncIterable, Any

async def llm_node(self, chat_ctx, tools, model_settings: Any):
    # ...

# âŒ WRONG (old - caused crash)
from livekit.agents import Agent, llm, ModelSettings  # ModelSettings doesn't exist!
```

### 2. Dependencies (Updated)
All dependencies MUST be in `requirements.txt`:
```txt
âœ… livekit-agents
âœ… supabase>=2.0.0          # Added Nov 7
âœ… Pillow>=10.0.0           # Added Nov 7
âœ… numpy>=1.24.0            # Added Nov 7
âœ… pydantic-ai-slim[openai,cmp]
âœ… requests
âœ… python-dotenv
```

### 3. Async/Await Rules
```python
# âœ… CORRECT: Async I/O
async def fetch_data():
    result = await db.query()
    return result

# âŒ WRONG: Blocking in async
async def fetch_data():
    result = db.query()  # Blocks event loop!
    return result
```

### 4. Error Handling
```python
# âœ… GOOD: Specific exceptions, logging
try:
    result = await api_call()
except OpenAIError as e:
    logger.error(f"OpenAI API failed: {e}")
    # Graceful fallback
    return default_response
except Exception as e:
    logger.exception("Unexpected error")
    raise

# âŒ BAD: Bare except
try:
    result = api_call()
except:  # Too broad!
    pass  # Silent failure!
```

### 5. Memory Management
```python
# âœ… GOOD: Limited buffer, cleanup
class ConversationManager:
    MAX_MESSAGES = 100

    def add_message(self, msg):
        self.messages.append(msg)
        if len(self.messages) > self.MAX_MESSAGES:
            self.messages = self.messages[-self.MAX_MESSAGES:]

# âŒ BAD: Unbounded growth
class ConversationManager:
    def add_message(self, msg):
        self.messages.append(msg)  # Grows forever!
```

---

## ğŸ¨ Frontend Standards

### Next.js/React Patterns
```typescript
// âœ… GOOD: TypeScript, proper hooks
import { useState, useEffect } from 'react';
import { Room } from 'livekit-client';

export const VideoCall: React.FC = () => {
  const [room, setRoom] = useState<Room | null>(null);

  useEffect(() => {
    return () => room?.disconnect();
  }, [room]);

  // ...
}

// âŒ BAD: No types, missing cleanup
export const VideoCall = () => {
  const [room, setRoom] = useState(null);
  // No cleanup - memory leak!
}
```

---

## ğŸ§ª Testing Requirements

### Unit Tests
```python
# tests/test_visual_context.py
import pytest
from visual_context_models import VisualContextStore

@pytest.mark.asyncio
async def test_visual_context_freshness():
    store = VisualContextStore()
    store.update("Test analysis")

    current = store.get_current()
    assert current is not None
    assert current.is_fresh is True
```

### Before Committing
```bash
# Run these checks:
1. pytest avatary/tests/           # All tests pass
2. mypy avatary/                   # Type checking
3. python agent.py dev             # Agent starts without errors
4. Check agent.log for errors      # No runtime errors
```

---

## ğŸ³ Docker Workflow

### Development
```bash
docker-compose up --build
# Backend: http://localhost:8080
# Frontend: http://localhost:3000
```

### Production
```bash
docker-compose -f docker-compose.prod.yml up -d
```

---

## ğŸ“Š Performance Targets

- **Agent Response Time:** < 2 seconds
- **Knowledge Base Search:** < 200ms (with cache)
- **Vision Analysis:** Every 3 seconds
- **Memory Usage:** < 500MB per agent instance
- **Conversation Buffer:** Max 100 messages

---

## ğŸ” Debugging

### Vision System Issues
```bash
# Check vision logs
tail -f avatary/agent.log | grep -E "ğŸ‘ï¸|âœ…|ğŸ’‰"

# Expected output:
# ğŸ‘ï¸  Visual analysis received: Ø£Ø±Ù‰ Ø´Ø®ØµÙ‹Ø§...
# âœ… Visual context stored
# ğŸ’‰ Injecting visual context (2.3s old)
```

### Agent Won't Start
```bash
# 1. Check Python syntax
cd avatary && python -m py_compile agent.py

# 2. Check imports
python -c "from visual_aware_agent import VisualAwareAgent"

# 3. Check .env
cat .env | grep -E "LIVEKIT|OPENAI|SUPABASE"
```

### Database Issues
```bash
# Test Supabase connection
python -c "
from knowledge_base_manager import KnowledgeBaseManager
kb = KnowledgeBaseManager()
print('âœ… Connected' if kb.client else 'âŒ Failed')
"
```

---

## ğŸš« DEPRECATED - DO NOT USE

| File/Pattern | Status | Use Instead |
|-------------|--------|-------------|
| `conversation_logger.py` | âŒ Deprecated | `ProfessionalConversationManager` |
| `conversation_context_manager.py` | âŒ Deprecated | `VisualAwareAgent` |
| Updating `agent.instructions` | âŒ Won't work | `llm_node` injection pattern |
| `session.say()` for context | âŒ Pollutes flow | `chat_ctx.add_message()` in llm_node |
| Synchronous Supabase calls | âŒ Slow | Async + connection pooling |

---

## ğŸ“š Key Documentation

- **Vision System:** `avatary/DEBUG_VISION.md`
- **Implementation Details:** `avatary/IMPLEMENTATION_SUMMARY.md`
- **Solution Architecture:** `avatary/VISUAL_CONTEXT_SOLUTION.md`
- **LiveKit Agents Docs:** https://docs.livekit.io/agents/
- **Supabase Docs:** https://supabase.com/docs

---

## ğŸ¯ Quick Start (New Developers)

1. **Read the architecture** in DEBUG_VISION.md
2. **Understand the flow:**
   - User connects â†’ Camera permission â†’ Video track
   - Vision processor captures frames (every 3s)
   - GPT-4 Vision analyzes â†’ Returns Arabic description
   - VisualAwareAgent stores in VisualContextStore (Pydantic)
   - User speaks â†’ llm_node triggered
   - Visual context injected as system message
   - LLM generates response with visual awareness
3. **Test the system:**
   - Hold up an object
   - Ask: "Ù…Ø§Ø°Ø§ ØªØ±Ù‰ØŸ" (What do you see?)
   - Avatar should describe it!

---

## âœ… When Stuck - Checklist

- [ ] Read DEBUG_VISION.md for visual context issues
- [ ] Check agent.log for runtime errors
- [ ] Verify all .env variables are set
- [ ] Ensure using VisualAwareAgent (not old patterns)
- [ ] Check LiveKit Agents documentation
- [ ] Test import: `python -c "from visual_aware_agent import VisualAwareAgent"`
- [ ] Verify dependencies: `pip install -r requirements.txt`
- [ ] Check git status for uncommitted changes
- [ ] Run tests: `pytest avatary/tests/`

---

**Last Updated:** November 7, 2025
**Critical Fix Applied:** ModelSettings import bug resolved
**Status:** Production-ready backend, Docker setup in progress
