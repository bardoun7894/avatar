# Vision System Debugging Guide

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER (Browser)                        â”‚
â”‚                  Camera + Microphone                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ LiveKit WebRTC
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LiveKit Room                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   User     â”‚â—„â”€â”€â–ºâ”‚  Agent   â”‚â—„â”€â”€â–ºâ”‚  Tavus Avatar     â”‚  â”‚
â”‚  â”‚  Tracks    â”‚    â”‚  Session â”‚    â”‚   (Video/Audio)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–²
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Backend Agent (agent.py)                    â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Vision Agent (vision_agent.py)                      â”‚  â”‚
â”‚  â”‚  - Monitors user video track                         â”‚  â”‚
â”‚  â”‚  - Captures frames every 5 seconds                   â”‚  â”‚
â”‚  â”‚  - Sends to GPT-4 Vision API                         â”‚  â”‚
â”‚  â”‚  - Returns Arabic description                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚               â”‚                                              â”‚
â”‚               â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Context Manager (conversation_context_manager.py)   â”‚  â”‚
â”‚  â”‚  - Receives visual analysis                          â”‚  â”‚
â”‚  â”‚  - Updates Agent instructions via Pydantic           â”‚  â”‚
â”‚  â”‚  - Injects context before each response              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚               â”‚                                              â”‚
â”‚               â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  LiveKit Agent                                       â”‚  â”‚
â”‚  â”‚  - Receives updated instructions                     â”‚  â”‚
â”‚  â”‚  - Generates responses via gpt-4o-mini               â”‚  â”‚
â”‚  â”‚  - Sends to Tavus Avatar                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚               â”‚                                              â”‚
â”‚               â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Tavus Avatar Integration                            â”‚  â”‚
â”‚  â”‚  - Receives text from Agent                          â”‚  â”‚
â”‚  â”‚  - Converts to speech (TTS)                          â”‚  â”‚
â”‚  â”‚  - Sends video/audio to user                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Module Organization

### Core Modules

1. **agent.py** - Main orchestrator
   - Sets up LiveKit Agent Session
   - Registers tools
   - Manages conversation lifecycle
   - Creates VisualAwareAgent instance

2. **visual_aware_agent.py** â­ NEW - Custom Agent with context injection
   - Extends LiveKit Agent class
   - Overrides `llm_node` method (LiveKit Agents 1.0 pattern)
   - Injects visual context as system message before each LLM call
   - Uses Pydantic models for clean data management

3. **visual_context_models.py** â­ NEW - Pydantic models
   - `VisualAnalysis` - Single analysis with timestamp
   - `VisualContextStore` - Thread-safe context storage
   - Automatic freshness checking
   - Clean data validation

4. **vision_agent.py** - Vision processing
   - Monitors video tracks
   - Captures frames
   - Analyzes with GPT-4 Vision

5. **vision_processor.py** - Low-level frame capture
   - Converts LiveKit video frames
   - Manages memory efficiently
   - Handles JPEG encoding

6. **conversation_context_manager.py** - DEPRECATED
   - Old approach (updating instructions)
   - Kept for backward compatibility
   - Delegates to VisualAwareAgent methods

7. **tavus_integration.py** - Tavus avatar API
   - Creates/manages Tavus conversations
   - Handles avatar lifecycle

## Debugging Steps

### 1. Check Vision Analysis is Working

```bash
tail -f /var/www/avatar\ /avatary/agent.log | grep "ðŸ‘ï¸"
```

**Expected output:**
```
ðŸ‘ï¸  Vision Agent: Analysis complete (234 chars)
ðŸ‘ï¸  Visual analysis: Ø£Ø±Ù‰ Ø´Ø®ØµÙ‹Ø§ ÙŠØ¬Ù„Ø³...
```

### 2. Check Instructions are Being Updated

```bash
tail -f /var/www/avatar\ /avatary/agent.log | grep "Agent instructions updated"
```

**Expected output:**
```
âœ… Agent instructions updated with visual context via Pydantic model
```

### 3. Check Agent Responses

```bash
tail -f /var/www/avatar\ /avatary/agent.log | grep -E "user|assistant"
```

### 4. Full Diagnostic

```bash
python3 diagnostic_tool.py
```

## Common Issues

### Issue 1: Vision works but avatar doesn't acknowledge âœ… SOLVED

**Symptoms:**
- âœ… Vision analysis shows correct descriptions
- âœ… Instructions updated
- âŒ Avatar doesn't mention what it sees

**Root Cause:**
Tavus Avatar may have its own instruction caching or the LiveKit Agent's updated instructions aren't being used for every turn.

**Solution (IMPLEMENTED):**
âœ… Created `VisualAwareAgent` class that overrides `llm_node` method
âœ… Injects visual context as system message into ChatContext before EACH LLM call
âœ… Uses LiveKit Agents 1.0 pattern (not deprecated `before_llm_cb`)
âœ… Uses Pydantic models for clean data management

**How It Works:**
1. Vision processor analyzes frame â†’ calls `agent.update_visual_context()`
2. Context stored in Pydantic `VisualContextStore`
3. When user speaks â†’ `llm_node` called automatically
4. `llm_node` injects fresh visual context as system message
5. LLM receives context â†’ generates response with visual awareness
6. Tavus avatar speaks response that acknowledges what it sees!

### Issue 2: Vision not starting

**Symptoms:**
- No "ðŸ“¹ Got user video track" messages
- No vision analysis logs

**Check:**
1. Camera permissions granted in browser
2. HTTPS connection (required for camera)
3. Video track is being published

### Issue 3: Memory leak

**Symptoms:**
- Process memory growing > 4GB
- Agent crashes

**Solution:**
- vision_processor.py properly closes streams
- JPEG quality reduced to 60%
- Analysis interval is 5 seconds

## Testing Visual Awareness

### Test Script

1. Connect to avatar
2. Hold up an object (book, phone, etc.)
3. Ask: "Ù…Ø§Ø°Ø§ ØªØ±Ù‰ØŸ" (What do you see?)
4. Avatar should describe the object

### Expected Behavior

Avatar should say something like:
> "Ø£Ø±Ù‰ Ø£Ù†Ùƒ ØªØ­Ù…Ù„ Ù‡Ø§ØªÙÙ‹Ø§ ÙÙŠ ÙŠØ¯Ùƒ" (I see you're holding a phone in your hand)

## Implementation Details (Current)

### Architecture Pattern: llm_node Override

The current implementation uses the **LiveKit Agents 1.0** pattern:

```python
class VisualAwareAgent(Agent):
    async def llm_node(self, chat_ctx, tools, model_settings):
        # Get fresh visual context from Pydantic store
        current_visual = self.visual_store.get_current()

        if current_visual and current_visual.is_fresh:
            # Inject as system message
            chat_ctx.add_message(
                role="system",
                content=current_visual.to_injection_text()
            )

        # Delegate to default LLM processing
        async for chunk in Agent.default.llm_node(self, chat_ctx, tools, model_settings):
            yield chunk
```

### Pydantic Models

**VisualAnalysis** - Represents a single vision analysis
```python
class VisualAnalysis(BaseModel):
    content: str  # Analysis text
    timestamp: datetime  # When created

    @property
    def is_fresh(self) -> bool:
        return self.age_seconds < 10
```

**VisualContextStore** - Thread-safe storage
```python
class VisualContextStore(BaseModel):
    latest_analysis: Optional[VisualAnalysis]
    max_age_seconds: float = 15.0
```

### Benefits of This Approach

1. âœ… **Reliable** - Context injected before EVERY LLM call
2. âœ… **Clean** - Uses Pydantic for type safety and validation
3. âœ… **Modern** - Uses LiveKit Agents 1.0 patterns (not deprecated APIs)
4. âœ… **Automatic** - No manual intervention needed
5. âœ… **Testable** - Easy to verify with `agent.get_visual_status()`

## Legacy Approaches (Not Recommended)

### âŒ Updating Instructions
Problem: Instructions may be cached by Tavus, not used every turn

### âŒ session.say() injection
Problem: Creates fake user messages, confuses conversation flow

### âŒ Prepending to user messages
Problem: Pollutes user input, hard to maintain

## File Locations

### Core Implementation
- Main agent: `/var/www/avatar /avatary/agent.py`
- Visual-aware agent: `/var/www/avatar /avatary/visual_aware_agent.py` â­ NEW
- Pydantic models: `/var/www/avatar /avatary/visual_context_models.py` â­ NEW
- Vision processor: `/var/www/avatar /avatary/vision_processor.py`
- Vision agent: `/var/www/avatar /avatary/vision_agent.py`

### Deprecated (backward compatibility)
- Context manager: `/var/www/avatar /avatary/conversation_context_manager.py` (use VisualAwareAgent instead)

### Configuration & Logs
- Vision logs: `/var/www/avatar /avatary/agent.log`
- Frontend logs: Browser console
- Configuration: `/var/www/avatar /avatary/.env`

## Quick Start

1. Start the agent (it will automatically use VisualAwareAgent)
2. Connect with camera enabled
3. Ask: "Ù…Ø§Ø°Ø§ ØªØ±Ù‰ØŸ" (What do you see?)
4. Avatar should describe what it sees!

## Monitoring

Check logs in real-time:
```bash
tail -f /var/www/avatar\ /avatary/agent.log | grep -E "ðŸ‘ï¸|âœ…|ðŸ’‰"
```

Expected output:
```
ðŸ‘ï¸  Visual analysis received: Ø£Ø±Ù‰ Ø´Ø®ØµÙ‹Ø§...
âœ… Visual context stored (will inject before next LLM call)
ðŸ’‰ Injecting visual context (2.3s old)
```
